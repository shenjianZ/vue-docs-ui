import OpenAI from 'openai'
import { getAIConfig, getCurrentAIProvider } from '../config/ai.js'

// AIæœåŠ¡ç±»
class AIService {
  constructor() {
    this.clients = new Map() // ç¼“å­˜ä¸åŒæä¾›å•†çš„å®¢æˆ·ç«¯
  }

  // èŽ·å–æˆ–åˆ›å»ºAIå®¢æˆ·ç«¯
  getClient(provider, config) {
    const clientKey = `${provider}-${config.baseUrl}-${config.apiKey?.slice(-8)}`
    
    if (!this.clients.has(clientKey)) {
      let client
      
      switch (provider) {
        case 'openai':
        case 'deepseek':
        case 'deepseek-v3':
        case 'deepseek-reasoner':
        case 'custom':
          // ä½¿ç”¨OpenAI SDKï¼Œæ”¯æŒDeepSeekå’Œå…¶ä»–å…¼å®¹API
          client = new OpenAI({
            baseURL: config.baseUrl,
            apiKey: config.apiKey,
            dangerouslyAllowBrowser: true // å…è®¸åœ¨æµè§ˆå™¨ä¸­ä½¿ç”¨
          })
          break
          
        case 'claude':
          // Anthropic Claude API (æš‚æ—¶ä½¿ç”¨OpenAIæ ¼å¼å…¼å®¹)
          client = new OpenAI({
            baseURL: config.baseUrl,
            apiKey: config.apiKey,
            dangerouslyAllowBrowser: true,
            defaultHeaders: {
              'anthropic-version': '2023-06-01',
              'content-type': 'application/json'
            }
          })
          break
          
        case 'gemini':
          // Google Gemini API (æš‚æ—¶ä½¿ç”¨OpenAIæ ¼å¼å…¼å®¹)
          client = new OpenAI({
            baseURL: config.baseUrl,
            apiKey: config.apiKey,
            dangerouslyAllowBrowser: true
          })
          break
          
        default:
          throw new Error(`ä¸æ”¯æŒçš„AIæä¾›å•†: ${provider}`)
      }
      
      this.clients.set(clientKey, client)
    }
    
    return this.clients.get(clientKey)
  }

  // å‘é€èŠå¤©æ¶ˆæ¯
  async sendMessage(message, context = {}) {
    try {
      const aiConfig = getAIConfig()
      const providerConfig = getCurrentAIProvider()
      
      if (!providerConfig.apiKey) {
        throw new Error('æœªé…ç½®APIå¯†é’¥')
      }

      const client = this.getClient(aiConfig.provider, providerConfig)
      
      // æž„å»ºæ¶ˆæ¯æ•°ç»„
      const messages = [
        {
          role: 'system',
          content: this.getSystemPrompt(context)
        },
        {
          role: 'user',
          content: message
        }
      ]

      // æ·»åŠ åŽ†å²æ¶ˆæ¯ä¸Šä¸‹æ–‡ï¼ˆå¦‚æžœæœ‰çš„è¯ï¼‰
      if (context.history && context.history.length > 0) {
        const historyMessages = context.history.slice(-4).map(msg => ({
          role: msg.type === 'user' ? 'user' : 'assistant',
          content: msg.text
        }))
        messages.splice(1, 0, ...historyMessages)
      }

      console.log('ðŸ¤– å‘é€AIè¯·æ±‚:', {
        provider: aiConfig.provider,
        model: providerConfig.modelId,
        messageCount: messages.length
      })

      // å‘é€è¯·æ±‚
      const completion = await client.chat.completions.create({
        model: providerConfig.modelId,
        messages: messages,
        max_tokens: providerConfig.maxTokens,
        temperature: providerConfig.temperature,
        stream: false
      })

      const response = completion.choices[0]?.message?.content
      
      if (!response) {
        throw new Error('AIå“åº”ä¸ºç©º')
      }

      console.log('âœ… AIå“åº”æˆåŠŸ')
      return response

    } catch (error) {
      console.error('âŒ AIè°ƒç”¨å¤±è´¥:', error)
      throw this.handleError(error)
    }
  }

  // èŽ·å–ç³»ç»Ÿæç¤ºè¯
  getSystemPrompt(context = {}) {
    const aiConfig = getAIConfig()
    const basePrompt = aiConfig.systemPrompt || `ä½ æ˜¯Vue Docs UIæ–‡æ¡£ç½‘ç«™çš„AIåŠ©æ‰‹ã€‚ä½ çš„ä»»åŠ¡æ˜¯å¸®åŠ©ç”¨æˆ·ç†è§£æ–‡æ¡£å†…å®¹ï¼Œå›žç­”æŠ€æœ¯é—®é¢˜ï¼Œå¹¶æä¾›æœ‰ç”¨çš„æŒ‡å¯¼ã€‚

è¯·éµå¾ªä»¥ä¸‹åŽŸåˆ™ï¼š
1. æä¾›å‡†ç¡®ã€æœ‰ç”¨çš„æŠ€æœ¯ä¿¡æ¯
2. ä¿æŒå‹å¥½ã€ä¸“ä¸šçš„è¯­è°ƒ
3. å¦‚æžœä¸ç¡®å®šç­”æ¡ˆï¼Œè¯·è¯šå®žåœ°è¯´æ˜Ž
4. å°½é‡ç»™å‡ºå…·ä½“çš„ä»£ç ç¤ºä¾‹æˆ–æ­¥éª¤
5. ä½¿ç”¨ä¸­æ–‡å›žç­”é—®é¢˜

ä½ ç‰¹åˆ«æ“…é•¿å›žç­”å…³äºŽï¼š
- Vue.js å¼€å‘
- ç»„ä»¶åº“ä½¿ç”¨
- æ–‡æ¡£ç¼–å†™å’Œç»´æŠ¤
- å‰ç«¯å¼€å‘æœ€ä½³å®žè·µ
- æŠ€æœ¯æ¦‚å¿µè§£é‡Š`

    // å¦‚æžœæœ‰å½“å‰é¡µé¢ä¸Šä¸‹æ–‡ï¼Œæ·»åŠ ç›¸å…³ä¿¡æ¯
    if (context.currentPage) {
      return `${basePrompt}\n\nå½“å‰ç”¨æˆ·æ­£åœ¨æŸ¥çœ‹é¡µé¢ï¼š${context.currentPage}`
    }

    if (context.documentContent) {
      return `${basePrompt}\n\nç›¸å…³æ–‡æ¡£å†…å®¹ï¼š\n${context.documentContent.slice(0, 1000)}`
    }

    return basePrompt
  }

  // æµ‹è¯•è¿žæŽ¥
  async testConnection() {
    try {
      const response = await this.sendMessage('ä½ å¥½ï¼Œè¯·å›žå¤ä¸€ä¸ªç®€çŸ­çš„æµ‹è¯•æ¶ˆæ¯ã€‚', {})
      return {
        success: true,
        message: 'è¿žæŽ¥æµ‹è¯•æˆåŠŸ',
        response: response
      }
    } catch (error) {
      return {
        success: false,
        message: error.message
      }
    }
  }

  // é”™è¯¯å¤„ç†
  handleError(error) {
    if (error.code === 'invalid_api_key') {
      return new Error('APIå¯†é’¥æ— æ•ˆï¼Œè¯·æ£€æŸ¥é…ç½®')
    }
    
    if (error.code === 'insufficient_quota') {
      return new Error('APIé…é¢ä¸è¶³ï¼Œè¯·æ£€æŸ¥è´¦æˆ·ä½™é¢')
    }
    
    if (error.code === 'rate_limit_exceeded') {
      return new Error('è¯·æ±‚é¢‘çŽ‡è¿‡é«˜ï¼Œè¯·ç¨åŽé‡è¯•')
    }
    
    if (error.code === 'model_not_found') {
      return new Error('æŒ‡å®šçš„æ¨¡åž‹ä¸å­˜åœ¨ï¼Œè¯·æ£€æŸ¥æ¨¡åž‹é…ç½®')
    }
    
    if (error.message?.includes('fetch')) {
      return new Error('ç½‘ç»œè¿žæŽ¥å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œå’ŒAPIç«¯ç‚¹')
    }
    
    if (error.message?.includes('CORS')) {
      return new Error('è·¨åŸŸè¯·æ±‚è¢«é˜»æ­¢ï¼Œè¯·æ£€æŸ¥APIé…ç½®')
    }
    
    return new Error(`AIè°ƒç”¨å¤±è´¥: ${error.message}`)
  }

  // æ¸…ç†ç¼“å­˜çš„å®¢æˆ·ç«¯
  clearClients() {
    this.clients.clear()
  }
}

// åˆ›å»ºå•ä¾‹å®žä¾‹
const aiService = new AIService()

export default aiService

// å¯¼å‡ºä¾¿æ·æ–¹æ³•
export const sendAIMessage = (message, context) => aiService.sendMessage(message, context)
export const testAIConnection = () => aiService.testConnection()
export const clearAIClients = () => aiService.clearClients() 